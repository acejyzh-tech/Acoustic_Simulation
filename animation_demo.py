import streamlit as st
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import threading
import time
from matplotlib.colors import LinearSegmentedColormap

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è‡ªå®šä¹‰é¢œè‰²æ˜ å°„ï¼ˆå¯é€‰ï¼‰
def create_custom_cmap():
    colors = ['#000000', '#1a237e', '#3949ab', '#3f51b5', '#5c6bc0', 
              '#7986cb', '#9fa8da', '#c5cae9', '#e8eaf6', '#ffffff']
    return LinearSegmentedColormap.from_list('audio_cmap', colors, N=256)

custom_cmap = create_custom_cmap()

# ä¸»åº”ç”¨
def main():
    st.title("ğŸµ WAVéŸ³é¢‘åˆ†æå·¥å…·")
    st.markdown("---")
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'audio_data' not in st.session_state:
        st.session_state.audio_data = None
    if 'sr' not in st.session_state:
        st.session_state.sr = None
    if 'duration' not in st.session_state:
        st.session_state.duration = 0.0
    if 'is_playing' not in st.session_state:
        st.session_state.is_playing = False
    if 'current_time' not in st.session_state:
        st.session_state.current_time = 0.0
    if 'spectrogram' not in st.session_state:
        st.session_state.spectrogram = None
    if 'freq_bins' not in st.session_state:
        st.session_state.freq_bins = None
    if 'time_bins' not in st.session_state:
        st.session_state.time_bins = None
    if 'lock' not in st.session_state:
        st.session_state.lock = threading.Lock()

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©WAVæ–‡ä»¶", type=["wav"])
    
    if uploaded_file is not None:
        # è¯»å–éŸ³é¢‘æ–‡ä»¶
        with st.spinner("æ­£åœ¨åŠ è½½éŸ³é¢‘..."):
            y, sr = librosa.load(uploaded_file, sr=None, mono=True)
            st.session_state.audio_data = y
            st.session_state.sr = sr
            st.session_state.duration = librosa.get_duration(y=y, sr=sr)
            
            # è®¡ç®—å£°è°±å›¾ï¼ˆSTFTï¼‰
            n_fft = 2048
            hop_length = 512
            D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)
            S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)
            
            st.session_state.spectrogram = S_db
            st.session_state.freq_bins = librosa.fft_frequencies(n_fft=n_fft)
            st.session_state.time_bins = librosa.times_like(D, sr=sr, hop_length=hop_length)
        
        # æ˜¾ç¤ºéŸ³é¢‘ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("é‡‡æ ·ç‡", f"{sr} Hz")
        with col2:
            st.metric("æ—¶é•¿", f"{st.session_state.duration:.2f} ç§’")
        with col3:
            st.metric("æ•°æ®ç‚¹æ•°", f"{len(y):,}")
        
        st.markdown("---")
        
        # éŸ³é¢‘æ’­æ”¾æ§ä»¶
        st.audio(uploaded_file, format="audio/wav", start_time=0)
        
        # æ’­æ”¾æ§åˆ¶æŒ‰é’®
        col_play, col_stop = st.columns(2)
        with col_play:
            play_btn = st.button("â–¶ï¸ æ’­æ”¾", type="primary")
        with col_stop:
            stop_btn = st.button("â¹ï¸ åœæ­¢")
        
        # è¿›åº¦æ¡
        progress_bar = st.progress(0.0)
        current_time_display = st.empty()
        
        # åˆ›å»ºåŒåˆ—å¸ƒå±€ï¼šå·¦ä¾§å£°è°±å›¾ï¼Œå³ä¾§å®æ—¶é¢‘è°±
        col_spectrogram, col_spectrum = st.columns(2)
        
        # ç»˜åˆ¶å£°è°±å›¾ï¼ˆå·¦ä¾§ï¼‰
        with col_spectrogram:
            st.subheader("å£°è°±å›¾ï¼ˆé¢‘ç‡Ã—æ—¶é—´ï¼‰")
            spectrogram_fig, ax = plt.subplots(figsize=(10, 6))
            
            # ç»˜åˆ¶å£°è°±å›¾
            im = ax.imshow(st.session_state.spectrogram, 
                          aspect='auto', 
                          origin='upper',  # æ—¶é—´è½´0ç‚¹åœ¨å·¦ä¸Šè§’
                          cmap=custom_cmap,
                          extent=[st.session_state.time_bins[0], 
                                 st.session_state.time_bins[-1], 
                                 st.session_state.freq_bins[0], 
                                 st.session_state.freq_bins[-1]])
            
            # è®¾ç½®æ ‡ç­¾
            ax.set_xlabel("æ—¶é—´ (ç§’)", fontsize=12)
            ax.set_ylabel("é¢‘ç‡ (Hz)", fontsize=12)
            ax.set_title("éŸ³é¢‘å£°è°±å›¾", fontsize=14, fontweight='bold')
            
            # æ·»åŠ é¢œè‰²æ¡
            cbar = plt.colorbar(im, ax=ax, label='å¼ºåº¦ (dB)')
            
            # åˆå§‹æ—¶é—´çº¿ï¼ˆçº¢è‰²è™šçº¿ï¼‰
            time_line = ax.axvline(x=0, color='red', linestyle='--', linewidth=2, label='å½“å‰æ’­æ”¾ä½ç½®')
            ax.legend(loc='upper right')
            
            st.pyplot(spectrogram_fig, use_container_width=True)
        
        # å®æ—¶é¢‘è°±å›¾ï¼ˆå³ä¾§ï¼‰
        with col_spectrum:
            st.subheader("å®æ—¶é¢‘è°±ï¼ˆdBå€¼ï¼‰")
            spectrum_fig, ax_spectrum = plt.subplots(figsize=(10, 6))
            
            # åˆå§‹åŒ–é¢‘è°±å›¾ï¼ˆå…¨é›¶ï¼‰
            freq_range = st.session_state.freq_bins
            init_spectrum = np.zeros_like(freq_range)
            line, = ax_spectrum.plot(freq_range, init_spectrum, color='#2196F3', linewidth=2)
            
            # è®¾ç½®æ ‡ç­¾å’ŒèŒƒå›´
            ax_spectrum.set_xlabel("é¢‘ç‡ (Hz)", fontsize=12)
            ax_spectrum.set_ylabel("å¼ºåº¦ (dB)", fontsize=12)
            ax_spectrum.set_title("å½“å‰æ’­æ”¾éŸ³é¢‘é¢‘è°±", fontsize=14, fontweight='bold')
            ax_spectrum.set_ylim(-100, 0)  # dBå€¼èŒƒå›´
            ax_spectrum.grid(True, alpha=0.3)
            
            # è®¾ç½®xè½´èŒƒå›´ï¼ˆå¯æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´ï¼‰
            max_freq = min(8000, sr//2)  # æœ€å¤§æ˜¾ç¤ºé¢‘ç‡ï¼š8kHzæˆ–å¥ˆå¥æ–¯ç‰¹é¢‘ç‡
            ax_spectrum.set_xlim(0, max_freq)
            
            spectrum_placeholder = st.empty()
            spectrum_placeholder.pyplot(spectrum_fig, use_container_width=True)
        
        # æ’­æ”¾çº¿ç¨‹å‡½æ•°
        def play_audio():
            st.session_state.is_playing = True
            start_time = time.time()
            
            while st.session_state.is_playing:
                # è®¡ç®—å½“å‰æ’­æ”¾æ—¶é—´
                elapsed_time = time.time() - start_time
                current_time = min(elapsed_time, st.session_state.duration)
                
                # æ›´æ–°ä¼šè¯çŠ¶æ€
                with st.session_state.lock:
                    st.session_state.current_time = current_time
                
                # æ›´æ–°è¿›åº¦æ¡
                progress = current_time / st.session_state.duration if st.session_state.duration > 0 else 0.0
                progress_bar.progress(progress)
                
                # æ›´æ–°æ—¶é—´æ˜¾ç¤º
                current_time_display.markdown(f"å½“å‰æ’­æ”¾æ—¶é—´: **{current_time:.2f} / {st.session_state.duration:.2f} ç§’**")
                
                # æ›´æ–°å£°è°±å›¾æ—¶é—´çº¿
                time_line.set_xdata(current_time)
                
                # è®¡ç®—å½“å‰æ—¶é—´ç‚¹çš„é¢‘è°±
                if st.session_state.audio_data is not None:
                    # æ‰¾åˆ°å½“å‰æ—¶é—´å¯¹åº”çš„éŸ³é¢‘å¸§
                    current_sample = int(current_time * st.session_state.sr)
                    
                    # å–å½“å‰å¸§é™„è¿‘çš„éŸ³é¢‘ç‰‡æ®µï¼ˆç”¨äºé¢‘è°±è®¡ç®—ï¼‰
                    window_size = n_fft  # ä¸STFTä¿æŒä¸€è‡´
                    start_sample = max(0, current_sample - window_size // 2)
                    end_sample = min(len(st.session_state.audio_data), current_sample + window_size // 2)
                    
                    # æå–éŸ³é¢‘ç‰‡æ®µå¹¶è¡¥é›¶ï¼ˆç¡®ä¿é•¿åº¦ä¸€è‡´ï¼‰
                    audio_segment = st.session_state.audio_data[start_sample:end_sample]
                    if len(audio_segment) < window_size:
                        audio_segment = np.pad(audio_segment, (0, window_size - len(audio_segment)), mode='constant')
                    
                    # è®¡ç®—é¢‘è°±
                    fft_result = np.fft.fft(audio_segment)
                    magnitude = np.abs(fft_result[:window_size//2])  # å–æ­£é¢‘ç‡éƒ¨åˆ†
                    magnitude_db = librosa.amplitude_to_db(magnitude, ref=np.max)
                    
                    # æ›´æ–°é¢‘è°±å›¾
                    line.set_ydata(magnitude_db)
                
                # åˆ·æ–°å›¾è¡¨
                with col_spectrogram:
                    st.pyplot(spectrogram_fig, use_container_width=True)
                with col_spectrum:
                    spectrum_placeholder.pyplot(spectrum_fig, use_container_width=True)
                
                # æ£€æŸ¥æ˜¯å¦æ’­æ”¾å®Œæ¯•
                if current_time >= st.session_state.duration:
                    st.session_state.is_playing = False
                    break
                
                # æ§åˆ¶æ›´æ–°é¢‘ç‡ï¼ˆé¿å…è¿‡äºé¢‘ç¹ï¼‰
                time.sleep(0.05)  # 50msæ›´æ–°ä¸€æ¬¡
        
        # æ’­æ”¾æŒ‰é’®é€»è¾‘
        if play_btn and not st.session_state.is_playing:
            # å¯åŠ¨æ’­æ”¾çº¿ç¨‹
            play_thread = threading.Thread(target=play_audio)
            play_thread.daemon = True
            play_thread.start()
        
        # åœæ­¢æŒ‰é’®é€»è¾‘
        if stop_btn:
            st.session_state.is_playing = False
            # é‡ç½®çŠ¶æ€
            st.session_state.current_time = 0.0
            progress_bar.progress(0.0)
            current_time_display.markdown(f"å½“å‰æ’­æ”¾æ—¶é—´: **0.00 / {st.session_state.duration:.2f} ç§’**")
            time_line.set_xdata(0)
            
            # é‡ç½®é¢‘è°±å›¾
            line.set_ydata(np.zeros_like(freq_range))
            with col_spectrogram:
                st.pyplot(spectrogram_fig, use_container_width=True)
            with col_spectrum:
                spectrum_placeholder.pyplot(spectrum_fig, use_container_width=True)
    
    else:
        # æœªä¸Šä¼ æ–‡ä»¶æ—¶çš„æç¤º
        st.info("è¯·ä¸Šä¼ ä¸€ä¸ªWAVæ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶è¿›è¡Œåˆ†æ")
        # æ˜¾ç¤ºç¤ºä¾‹å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
        col1, col2, col3 = st.columns(3)
        with col2:
            st.image("https://via.placeholder.com/400x300?text=ç­‰å¾…éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ ", use_column_width=True)

if __name__ == "__main__":
    main()
